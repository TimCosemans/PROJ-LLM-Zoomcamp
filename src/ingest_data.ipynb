{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a46d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timcosemans/Documents/PROJ-LLM-Zoomcamp/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d461147",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER  = \"huggingface\"\n",
    "ENCODER_MODEL = \"intfloat/multilingual-e5-small\" \n",
    "LLM_MODEL = \"llama3.2\"\n",
    "INDEX_NAME = \"llm-doc\"\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66a13c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timcosemans/Documents/PROJ-LLM-Zoomcamp/venv/lib/python3.13/site-packages/elasticsearch/_sync/client/__init__.py:311: SecurityWarning: Connecting to 'https://localhost:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n"
     ]
    }
   ],
   "source": [
    "#https://discuss.elastic.co/t/issue-connecting-python-to-elasticsearch-in-docker-environment/361507/2\n",
    "es_client = Elasticsearch(\n",
    "    hosts=[\"https://localhost:9200\"],\n",
    "    basic_auth=('elastic', os.getenv(\"ELASTIC_PASSWORD\")),\n",
    "    verify_certs=False,\n",
    "    max_retries=30,\n",
    "    retry_on_timeout=True,\n",
    "    request_timeout=30,\n",
    ")\n",
    "\n",
    "ollama = Client(host='https://localhost:11434')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dba331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_search_term = model.encode(search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b362dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timcosemans/Documents/PROJ-LLM-Zoomcamp/venv/lib/python3.13/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "\n",
    "knn_query = {\n",
    "    \"field\": \"question_encoded\",\n",
    "    \"query_vector\": vector_search_term,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 10000, \n",
    "}\n",
    "query = {\n",
    "    \"match\": {\n",
    "      \"question\": {\n",
    "        \"query\": search_term,\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "res = es_client.search(index=INDEX_NAME, \n",
    "                       query=query, knn=knn_query, source=[\"text\", \"section\", \"question\", \"course\"])\n",
    "for hit in res['hits']['hits']:\n",
    "        context.append(hit['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d6b7319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Yes, but if you want to receive a certificate, you need to submit your project while weâ€™re still accepting submissions.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'I just discovered the course. Can I still join?'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def setup_model(model_name):\n",
    "    \"\"\"Download and setup the Ollama model if not available.\"\"\"\n",
    "    try:\n",
    "        ollama.show(f'{model_name}:latest')\n",
    "    except:\n",
    "        print(f\"Downloading {model_name}...\")\n",
    "        ollama.pull(f'{model_name}:latest')\n",
    "\n",
    "def generate_response(query: str, context: str) -> str:\n",
    "    \"\"\"Generate response using Ollama with retrieved context.\"\"\"\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in context:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "\n",
    "\n",
    "    response = ollama.generate(\n",
    "        model=model_name,\n",
    "        prompt=prompt,\n",
    "        options={\n",
    "            'temperature': 0.7,\n",
    "            'top_p': 0.9,\n",
    "            'max_tokens': 500\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response['response']\n",
    "\n",
    "def rag(query):\n",
    "    search_results = elastic_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://collabnix.com/building-rag-applications-with-ollama-and-python-complete-2025-tutorial/\n",
    "\n",
    "https://github.com/ollama/ollama-python?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e9bbf",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "https://www.elastic.co/docs/solutions/search/search-approaches\n",
    "\n",
    "Full-text search uses bm25 on the text and query directly. \n",
    "Vector search can be based ond dense vectors (and knn to find similar vectors) or sparse vectors. \n",
    "Among sparse vector models, ES provides ELSER. This basically uses BERT encoding to generate synonyms based on sequences of words in the query and content. \n",
    "The n highest scoring words are taken as expansion tokens and mapped back to a sparse vector.\n",
    "\n",
    "Hybrid search uses vector and full-text search together.\n",
    "Semantic search provides managed workflows that use vector search under the hood.\n",
    "\n",
    "https://www.elastic.co/docs/reference/elasticsearch/clients/python/examples\n",
    "https://github.com/elastic/elasticsearch-labs/tree/main/notebooks/search\n",
    "\n",
    "ELSER is most easy to use, but not available in the free version of ES.\n",
    "Plan\n",
    "- Use hugging face to create a dense representation of question field of documents\n",
    "- Create mapping (https://www.elastic.co/docs/solutions/search/vector/knn)\n",
    "- Create index \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
